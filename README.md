## Sign Language Model Project

Uses LSTM for ASL action recognition

## ğŸ“ Dataset Folder Structure in Google

dataset/
   â”œâ”€â”€ hello/
   â”‚     â”œâ”€â”€ hello_1.mp4
   â”‚     â”œâ”€â”€ hello_2.mp4
   â”‚     â”œâ”€â”€ ...
   â”‚
   â”œâ”€â”€ thank_you/
   â”‚     â”œâ”€â”€ thank_you_1.mp4
   â”‚     â”œâ”€â”€ thank_you_2.mp4
   â”‚     â”œâ”€â”€ ...
   â”‚
   â”œâ”€â”€ yes/
   â”‚     â”œâ”€â”€ yes_1.mp4
   â”‚     â”œâ”€â”€ yes_2.mp4
   â”‚     â”œâ”€â”€ ...
   â”‚
   â””â”€â”€ no/
         â”œâ”€â”€ no_1.mp4
         â”œâ”€â”€ no_2.mp4
         â”œâ”€â”€ ...

### NOTE
- ğŸ¥ How Many Videos per Action?
-- Minimum: 30â€“50 videos per action
- â± Video Length
-- Ideal length: 2â€“4 seconds per video
-- Keep frame rate at 30 FPS (default in most devices)
- ğŸ“Œ Tips for Recording
-- Vary background and lighting slightly to make the model robust.
-- Record from slightly different positions/angles.
-- Include different people performing the sign if possible.
-- Keep hands fully in frame â€” especially important for two-hand signs.
-- For two-hand detection, make sure both hands are clearly visible in most frames.